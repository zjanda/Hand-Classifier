{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from helpers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0. 503. 389.   0.]\n",
      "  [  1. 436. 368.   0.]\n",
      "  [  2. 379. 316.   0.]\n",
      "  ...\n",
      "  [ 18. 550. 215.   0.]\n",
      "  [ 19. 538. 261.   0.]\n",
      "  [ 20. 527. 297.   0.]]\n",
      "\n",
      " [[  0. 505. 387.   0.]\n",
      "  [  1. 438. 366.   0.]\n",
      "  [  2. 379. 316.   0.]\n",
      "  ...\n",
      "  [ 18. 548. 214.   0.]\n",
      "  [ 19. 536. 259.   0.]\n",
      "  [ 20. 527. 296.   0.]]\n",
      "\n",
      " [[  0. 502. 388.   0.]\n",
      "  [  1. 435. 365.   0.]\n",
      "  [  2. 378. 314.   0.]\n",
      "  ...\n",
      "  [ 18. 547. 214.   0.]\n",
      "  [ 19. 535. 258.   0.]\n",
      "  [ 20. 526. 294.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0. 467. 340.   5.]\n",
      "  [  1. 422. 326.   5.]\n",
      "  [  2. 386. 297.   5.]\n",
      "  ...\n",
      "  [ 18. 539. 212.   5.]\n",
      "  [ 19. 558. 191.   5.]\n",
      "  [ 20. 574. 172.   5.]]\n",
      "\n",
      " [[  0. 466. 340.   5.]\n",
      "  [  1. 421. 326.   5.]\n",
      "  [  2. 385. 297.   5.]\n",
      "  ...\n",
      "  [ 18. 539. 211.   5.]\n",
      "  [ 19. 558. 191.   5.]\n",
      "  [ 20. 573. 172.   5.]]\n",
      "\n",
      " [[  0. 466. 340.   5.]\n",
      "  [  1. 421. 326.   5.]\n",
      "  [  2. 385. 297.   5.]\n",
      "  ...\n",
      "  [ 18. 539. 211.   5.]\n",
      "  [ 19. 558. 191.   5.]\n",
      "  [ 20. 573. 172.   5.]]]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data.txt', delimiter=' ')\n",
    "# reshape set up hands to be normalized\n",
    "data = data.reshape((-1, 21, data.shape[1]))\n",
    "print(data)\n",
    "# np.random.shuffle(data)\n",
    "# print(data.shape)\n",
    "data = torch.from_numpy(data)\n",
    "# data = data[torch.randperm(data.size()[0])] # shuffles train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 39774\n",
      "ic| y[y == fingers_count].shape[0]: 39774\n",
      "ic| y[y == fingers_count].shape[0]: 39732\n",
      "ic| y[y == fingers_count].shape[0]: 39606\n",
      "ic| y[y == fingers_count].shape[0]: 39753\n"
     ]
    }
   ],
   "source": [
    "X, y = data[..., :-1], data[..., -1]\n",
    "# inspect distribution of data, if unbalanced then balance\n",
    "for fingers_count in range(6):\n",
    "    ic(y[y == fingers_count].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y_shapes: [1793, 1894, 1894, 1892, 1886, 1893]\n",
      "ic| bal_indices.shape: (10758,)\n",
      "ic| X_new.shape: torch.Size([10758, 21, 3])\n",
      "ic| y_new.shape: torch.Size([10758, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([10758, 21])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance data\n",
    "y_shapes = []\n",
    "temp_y = y[:, 0]\n",
    "unbal_indices = []\n",
    "for fingers_count in torch.arange(np.unique(temp_y).shape[0]):\n",
    "    unbal_indices.append(np.where(temp_y == fingers_count)[0])\n",
    "    shape_ = unbal_indices[fingers_count].shape[0]\n",
    "    y_shapes.append(shape_)\n",
    "\n",
    "ic(y_shapes)\n",
    "bal_indices = []\n",
    "min_shape = min(y_shapes)\n",
    "for fingers_count in range(len(unbal_indices)):\n",
    "    bal_indices.append(unbal_indices[fingers_count][0:min_shape])\n",
    "\n",
    "# ic(bal_indices)\n",
    "bal_indices = np.array(bal_indices).flatten()\n",
    "ic(bal_indices.shape)\n",
    "y_new = y[bal_indices]\n",
    "X_new = X[bal_indices]\n",
    "ic(X_new.shape)\n",
    "ic(y_new.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 37653\n",
      "ic| y[y == fingers_count].shape[0]: 37653\n"
     ]
    }
   ],
   "source": [
    "X = X_new\n",
    "y = y_new\n",
    "\n",
    "for fingers_count in range(6):\n",
    "    ic(y[y == fingers_count].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Normalize each hand relative to itself. Removes dependency of hand positioning in camera field of view\n",
    "for i, hand in enumerate(X):\n",
    "    X[i] = normalize_hand(hand)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.x.shape: torch.Size([10758, 21, 3])\n",
      "    self.y.shape: torch.Size([10758, 21])\n",
      "ic| reshaped_y.shape: torch.Size([10758, 21, 1])\n",
      "ic| self.x.shape: torch.Size([10758, 21, 3])\n",
      "    self.y.shape: torch.Size([10758, 21])\n",
      "ic| reshaped_y.shape: torch.Size([10758, 21, 1])\n"
     ]
    }
   ],
   "source": [
    "class HandDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x, self.y = data[..., :-1], data[..., -1]\n",
    "        self.n_samples = y.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ic(self.x.shape, self.y.shape)\n",
    "        reshaped_y = self.y.reshape(-1, 21, 1)\n",
    "        ic(reshaped_y.shape)\n",
    "        return torch.cat([self.x[index], reshaped_y[index]], dim=-1)\n",
    "\n",
    "    def split(self, test_size=.2):\n",
    "        split = int(self.x.shape[0] * (1 -test_size))\n",
    "        return self[:split, :], self[split:, :]  # train, test\n",
    "\n",
    "# Combine X and y to preserve data during shuffle\n",
    "reshaped_y = y.reshape(-1, 21, 1)\n",
    "data = torch.cat([X, reshaped_y], dim=-1)\n",
    "\n",
    "# Shuffle\n",
    "dataset = HandDataset(data[torch.randperm(data.shape[0])]) # shuffles train_dataset\n",
    "train_dataset, test_dataset = dataset.split()\n",
    "\n",
    "# hyper parameters\n",
    "### DEFINED IN helpers.py\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "# for i in range(len(train_loader)):\n",
    "#     print(train_loader.dataset[i, 0, 3].item())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_dataset): 8606\n",
      "ic| len(train_loader): 87\n",
      "ic| len(test_dataset): 2152\n",
      "ic| len(test_loader): 22\n"
     ]
    },
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(train_dataset))\n",
    "ic(len(train_loader))\n",
    "ic(len(test_dataset))\n",
    "ic(len(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| input_size: 63\n",
      "ic| hidden_size: 50\n",
      "ic| num_classes: 6\n",
      "87it [00:00, 140.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/3, loss = 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:00, 632.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/3, loss = 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:00, 665.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/3, loss = 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = NeuralNet(ic(input_size), ic(hidden_size), ic(num_classes))\n",
    "\n",
    "# loss and optimization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def normalize_hands(hands):\n",
    "    for i, hand in enumerate(hands):\n",
    "        hands[i] = torch.from_numpy(normalize_hand(hand.np()).astype(np.float32()))\n",
    "    return hands\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "sc = StandardScaler()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, sample in tqdm(enumerate(train_loader)):\n",
    "        hands, labels = sample[..., :-1].float(), sample[..., -1][:, 0].long()\n",
    "\n",
    "        # hands = normalize_hands(hands).float()\n",
    "        hands = hands.reshape(-1, input_size)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(hands).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i + 1 == len(train_loader):\n",
    "            print(f'epoch {epoch + 1}/{num_epochs}, loss = {loss.item():.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| i: 1, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 2, labels.shape[0]: 100, (pred == labels).sum().item(): 97\n",
      "ic| i: 3, labels.shape[0]: 100, (pred == labels).sum().item(): 97\n",
      "ic| i: 4, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 5, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 6, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 7, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 8, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 9, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 10, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 11, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 12, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 13, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 14, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 15, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 16, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 17, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 18, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 19, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 20, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 21, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 22, labels.shape[0]: 52, (pred == labels).sum().item(): 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 99.44237918215613\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    i = 1\n",
    "    for sample in test_loader:\n",
    "        hands, labels = sample[..., :-1].float(), sample[..., -1][:, 0].long()\n",
    "\n",
    "        # hands = normalize_hands(hands).float()\n",
    "        hands = hands.reshape(-1, input_size)\n",
    "\n",
    "        outputs = model(hands)\n",
    "\n",
    "        # value, index\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "\n",
    "        ic(i, labels.shape[0], (pred == labels).sum().item())\n",
    "        i += 1\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()\n",
    "\n",
    "    acc = 100 * n_correct / n_samples\n",
    "\n",
    "    print('accuracy =', acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "save_model(model.state_dict(), 'finalized_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}