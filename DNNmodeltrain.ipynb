{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from helpers import *\n",
    "from tqdm import tqdm\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0. 503. 389.   0.]\n",
      "  [  1. 436. 368.   0.]\n",
      "  [  2. 379. 316.   0.]\n",
      "  ...\n",
      "  [ 18. 550. 215.   0.]\n",
      "  [ 19. 538. 261.   0.]\n",
      "  [ 20. 527. 297.   0.]]\n",
      "\n",
      " [[  0. 505. 387.   0.]\n",
      "  [  1. 438. 366.   0.]\n",
      "  [  2. 379. 316.   0.]\n",
      "  ...\n",
      "  [ 18. 548. 214.   0.]\n",
      "  [ 19. 536. 259.   0.]\n",
      "  [ 20. 527. 296.   0.]]\n",
      "\n",
      " [[  0. 502. 388.   0.]\n",
      "  [  1. 435. 365.   0.]\n",
      "  [  2. 378. 314.   0.]\n",
      "  ...\n",
      "  [ 18. 547. 214.   0.]\n",
      "  [ 19. 535. 258.   0.]\n",
      "  [ 20. 526. 294.   0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0. 205. 346.   5.]\n",
      "  [  1. 258. 328.   5.]\n",
      "  [  2. 295. 293.   5.]\n",
      "  ...\n",
      "  [ 18. 141. 205.   5.]\n",
      "  [ 19. 127. 183.   5.]\n",
      "  [ 20. 115. 161.   5.]]\n",
      "\n",
      " [[  0. 204. 347.   5.]\n",
      "  [  1. 257. 329.   5.]\n",
      "  [  2. 294. 292.   5.]\n",
      "  ...\n",
      "  [ 18. 139. 206.   5.]\n",
      "  [ 19. 125. 183.   5.]\n",
      "  [ 20. 113. 161.   5.]]\n",
      "\n",
      " [[  0. 204. 347.   5.]\n",
      "  [  1. 257. 329.   5.]\n",
      "  [  2. 295. 293.   5.]\n",
      "  ...\n",
      "  [ 18. 140. 206.   5.]\n",
      "  [ 19. 126. 183.   5.]\n",
      "  [ 20. 113. 161.   5.]]]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('data.txt', delimiter=' ')\n",
    "# reshape set up hands to be normalized\n",
    "data = data.reshape((-1, 21, data.shape[1]))\n",
    "print(data)\n",
    "# np.random.shuffle(data)\n",
    "# print(data.shape)\n",
    "data = torch.from_numpy(data)\n",
    "# data = data[torch.randperm(data.size()[0])] # shuffles train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 53088\n",
      "ic| y[y == fingers_count].shape[0]: 53004\n",
      "ic| y[y == fingers_count].shape[0]: 52941\n",
      "ic| y[y == fingers_count].shape[0]: 52794\n",
      "ic| y[y == fingers_count].shape[0]: 52983\n"
     ]
    }
   ],
   "source": [
    "X, y = data[..., :-1], data[..., -1]\n",
    "# inspect distribution of data, if unbalanced then balance\n",
    "for fingers_count in range(6):\n",
    "    ic(y[y == fingers_count].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y_shapes: [2391, 2528, 2524, 2521, 2514, 2523]\n",
      "ic| bal_indices.shape: (14346,)\n",
      "ic| X_new.shape: torch.Size([14346, 21, 3])\n",
      "ic| y_new.shape: torch.Size([14346, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([14346, 21])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balance data\n",
    "y_shapes = []\n",
    "temp_y = y[:, 0]\n",
    "unbal_indices = []\n",
    "for fingers_count in torch.arange(np.unique(temp_y).shape[0]):\n",
    "    unbal_indices.append(np.where(temp_y == fingers_count)[0])\n",
    "    shape_ = unbal_indices[fingers_count].shape[0]\n",
    "    y_shapes.append(shape_)\n",
    "\n",
    "ic(y_shapes)\n",
    "bal_indices = []\n",
    "min_shape = min(y_shapes)\n",
    "for fingers_count in range(len(unbal_indices)):\n",
    "    bal_indices.append(unbal_indices[fingers_count][0:min_shape])\n",
    "\n",
    "# ic(bal_indices)\n",
    "bal_indices = np.array(bal_indices).flatten()\n",
    "ic(bal_indices.shape)\n",
    "y_new = y[bal_indices]\n",
    "X_new = X[bal_indices]\n",
    "ic(X_new.shape)\n",
    "ic(y_new.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 50211\n",
      "ic| y[y == fingers_count].shape[0]: 50211\n"
     ]
    }
   ],
   "source": [
    "X = X_new\n",
    "y = y_new\n",
    "\n",
    "for fingers_count in range(6):\n",
    "    ic(y[y == fingers_count].shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Normalize each hand relative to itself. Removes dependency of hand positioning in camera field of view\n",
    "for i, hand in enumerate(X):\n",
    "    X[i] = normalize_hand(hand)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.x.shape: torch.Size([14346, 21, 3])\n",
      "    self.y.shape: torch.Size([14346, 21])\n",
      "ic| reshaped_y.shape: torch.Size([14346, 21, 1])\n",
      "ic| self.x.shape: torch.Size([14346, 21, 3])\n",
      "    self.y.shape: torch.Size([14346, 21])\n",
      "ic| reshaped_y.shape: torch.Size([14346, 21, 1])\n"
     ]
    }
   ],
   "source": [
    "class HandDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x, self.y = data[..., :-1], data[..., -1]\n",
    "        self.n_samples = y.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ic(self.x.shape, self.y.shape)\n",
    "        reshaped_y = self.y.reshape(-1, 21, 1)\n",
    "        ic(reshaped_y.shape)\n",
    "        return torch.cat([self.x[index], reshaped_y[index]], dim=-1)\n",
    "\n",
    "    def split(self, test_size=.2):\n",
    "        split = int(self.x.shape[0] * (1 - test_size))\n",
    "        return self[:split, :], self[split:, :]  # train, test\n",
    "\n",
    "\n",
    "# Combine X and y to preserve data during shuffle\n",
    "reshaped_y = y.reshape(-1, 21, 1)\n",
    "data = torch.cat([X, reshaped_y], dim=-1)\n",
    "\n",
    "# Shuffle\n",
    "dataset = HandDataset(data[torch.randperm(data.shape[0])])  # shuffles train_dataset\n",
    "train_dataset, test_dataset = dataset.split()\n",
    "\n",
    "# hyper parameters\n",
    "### DEFINED IN helpers.py\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "# for i in range(len(train_loader)):\n",
    "#     print(train_loader.dataset[i, 0, 3].item())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_dataset): 11476\n",
      "ic| len(train_loader): 115\n",
      "ic| len(test_dataset): 2870\n",
      "ic| len(test_loader): 29\n"
     ]
    },
    {
     "data": {
      "text/plain": "29"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(train_dataset))\n",
    "ic(len(train_loader))\n",
    "ic(len(test_dataset))\n",
    "ic(len(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| input_size: 63\n",
      "ic| hidden_size: 50\n",
      "ic| num_classes: 6\n",
      "  6%|▌         | 3/50 [00:00<00:04, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50, loss = 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:00<00:04, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/50, loss = 0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:01<00:03, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/50, loss = 0.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:01<00:03, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16/50, loss = 0.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:02<00:02, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21/50, loss = 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:02<00:02, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26/50, loss = 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:03<00:01, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31/50, loss = 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:03<00:01, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36/50, loss = 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:03<00:00, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41/50, loss = 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:04<00:00, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46/50, loss = 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.78it/s]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = NeuralNet(ic(input_size), ic(hidden_size), ic(num_classes)).to(device)\n",
    "# loss and optimization\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def normalize_hands(hands):\n",
    "    for i, hand in enumerate(hands):\n",
    "        hands[i] = torch.from_numpy(normalize_hand(hand.np()).astype(np.float32()))\n",
    "    return hands\n",
    "\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        # extract data from sample\n",
    "        hands = sample[..., :-1].float().to(device)\n",
    "        labels = sample[..., -1][:, 0].long().to(device)\n",
    "\n",
    "        # hands = normalize_hands(hands).float()\n",
    "        hands = hands.reshape(-1, input_size)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(hands).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # if epoch % 5 == 0:\n",
    "    #     print(f'epoch {epoch + 1}/{num_epochs}, loss = {loss.item():.4f}')\n",
    "\n",
    "print('Training Complete!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| i: 1, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 2, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 3, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 4, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 5, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 6, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 7, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 8, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 9, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 10, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 11, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 12, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 13, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 14, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 15, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 16, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 17, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 18, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 19, labels.shape[0]: 100, (pred == labels).sum().item(): 98\n",
      "ic| i: 20, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 21, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 22, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 23, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 24, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 25, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 26, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 27, labels.shape[0]: 100, (pred == labels).sum().item(): 99\n",
      "ic| i: 28, labels.shape[0]: 100, (pred == labels).sum().item(): 100\n",
      "ic| i: 29, labels.shape[0]: 70, (pred == labels).sum().item(): 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 99.30313588850174\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    i = 1\n",
    "    for sample in test_loader:\n",
    "        hands = sample[..., :-1].float().to(device)\n",
    "        labels = sample[..., -1][:, 0].long().to(device)\n",
    "\n",
    "        # hands = normalize_hands(hands).float()\n",
    "        hands = hands.reshape(-1, input_size)\n",
    "\n",
    "        outputs = model(hands)\n",
    "\n",
    "        # value, index\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "\n",
    "        # ic(i, labels.shape[0], (pred == labels).sum().item())\n",
    "        i += 1\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()\n",
    "\n",
    "    acc = 100 * n_correct / n_samples\n",
    "\n",
    "    print('accuracy =', acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "save_model(model.state_dict(), 'finalized_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}